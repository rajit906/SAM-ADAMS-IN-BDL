{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8dce676",
   "metadata": {},
   "source": [
    "# Reproduction: Neal's Funnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec006424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c11a020d33149eeb23f568167ba473c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatLogSlider(value=1.0, description='alpha', max=2.0, min=-2.0), FloatLogSlider(value=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import njit\n",
    "from ipywidgets import interact, FloatLogSlider\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- Neal's funnel potential ---\n",
    "@njit\n",
    "def grad_U(z):\n",
    "    y, x = z\n",
    "    grad_y = y - 0.5 * np.exp(-y) * (x**2)\n",
    "    grad_x = np.exp(-y) * x\n",
    "    return np.array([grad_y, grad_x])\n",
    "\n",
    "@njit\n",
    "def laplacian_U(z):\n",
    "    y, x = z\n",
    "    return 1.0 + np.exp(-y) + 0.5 * np.exp(-y) * x**2\n",
    "\n",
    "# --- BAOAB integrator ---\n",
    "@njit\n",
    "def step_BAOAB(x, p, z, h, gamma, alpha, beta):\n",
    "    dt = h\n",
    "    p -= 0.5*dt*grad_U(x)\n",
    "    x += 0.5*dt*p\n",
    "    c = np.exp(-gamma*dt)\n",
    "    p = c*p + np.sqrt((1-c**2) / beta)*np.random.randn(2)\n",
    "    x += 0.5*dt*p\n",
    "    p -= 0.5*dt*grad_U(x)\n",
    "    return x, p, z, dt\n",
    "\n",
    "@njit\n",
    "def g(x):\n",
    "    return np.linalg.norm(grad_U(x))\n",
    "\n",
    "@njit\n",
    "def psi(z, m, M, r):\n",
    "    return m * (z**r + M) / (z**r + m)\n",
    "\n",
    "# --- ZBAOABZ integrator ---\n",
    "@njit\n",
    "def step_ZBAOABZ(x, p, z, dtau, gamma, alpha, beta):\n",
    "    rho = np.exp(-alpha*0.5*dtau)\n",
    "    z = rho*z + (1-rho) * g(x) / alpha\n",
    "    dt = psi(z, m, M, r) * dtau\n",
    "\n",
    "    p -= 0.5*dt*grad_U(x)\n",
    "    x += 0.5*dt*p\n",
    "    c = np.exp(-gamma*dt)\n",
    "    p = c*p + np.sqrt((1-c**2) / beta)*np.random.randn(2)\n",
    "    x += 0.5*dt*p\n",
    "    p -= 0.5*dt*grad_U(x)\n",
    "\n",
    "    rho = np.exp(-alpha*0.5*dtau)\n",
    "    z = rho*z + (1-rho) * g(x) / alpha\n",
    "    return x, p, z, dt\n",
    "\n",
    "# --- Run sampler with optional trace recording ---\n",
    "@njit\n",
    "def run_sampler(stepper, nsteps, h, gamma, alpha, beta, burnin=1000, record_trace=False):\n",
    "    x = np.array([5.0, 0.0])\n",
    "    p = np.array([0.0, 0.0])\n",
    "    z = 0.0\n",
    "    samples = np.zeros((nsteps, 2))\n",
    "    traces = np.zeros((nsteps, 6))  # [y, x, p_y, p_x, dt, T_conf]\n",
    "\n",
    "    for t in range(nsteps + burnin):\n",
    "        x, p, z, dt = stepper(x, p, z, h, gamma, alpha, beta)\n",
    "        if t >= burnin:\n",
    "            idx = t - burnin\n",
    "            samples[idx, 0] = x[0]   # y\n",
    "            samples[idx, 1] = x[1]   # x\n",
    "            if record_trace:\n",
    "                grad = grad_U(x)\n",
    "                lapl = laplacian_U(x)\n",
    "                T_conf = np.dot(grad, grad) / lapl\n",
    "\n",
    "                traces[idx, 0] = x[0]    # y\n",
    "                traces[idx, 1] = x[1]    # x\n",
    "                traces[idx, 2] = p[0]    # p_y\n",
    "                traces[idx, 3] = p[1]    # p_x\n",
    "                traces[idx, 4] = dt      # dt\n",
    "                traces[idx, 5] = T_conf  # configurational T\n",
    "    return samples, traces\n",
    "\n",
    "# --- Effective Sample Size ---\n",
    "def autocorr_func_1d(x, max_lag=2000):\n",
    "    n = len(x)\n",
    "    x = x - np.mean(x)\n",
    "    result = np.correlate(x, x, mode='full')\n",
    "    acf = result[result.size//2:] / result[result.size//2]\n",
    "    return acf[:max_lag]\n",
    "\n",
    "def ess(x, max_lag=2000):\n",
    "    acf = autocorr_func_1d(x, max_lag)\n",
    "    positive_acf = acf[acf > 0]\n",
    "    tau = 1 + 2 * np.sum(positive_acf[1:])\n",
    "    return len(x) / tau\n",
    "\n",
    "# --- Target log density for contours ---\n",
    "def log_p(y, x):\n",
    "    return -0.5*y**2 - 0.5*np.exp(-y)*x**2\n",
    "\n",
    "xs = np.linspace(-10, 10, 400)\n",
    "ys = np.linspace(-6, 6, 300)\n",
    "X, Y = np.meshgrid(xs, ys)\n",
    "LOGZ = log_p(Y, X)\n",
    "vmax, vmin = LOGZ.max(), LOGZ.max() - 40\n",
    "levels = np.linspace(vmin, vmax, 60)\n",
    "m, M, r = 0.01, 60, 0.5\n",
    "\n",
    "def plot_samplers(alpha=1.0, h=0.01, gamma=1.0, beta=1.0):\n",
    "    nsteps = int(1e4)  # keep interactive speed reasonable\n",
    "\n",
    "    samples_baoab, traces_baoab = run_sampler(step_BAOAB, nsteps, h, gamma, alpha, beta, record_trace=True)\n",
    "    samples_zbaoabz, traces_zbaoabz = run_sampler(step_ZBAOABZ, nsteps, h, gamma, alpha, beta, record_trace=True)\n",
    "\n",
    "    # compute ESS for y trace\n",
    "    ess_baoab = ess(traces_baoab[:,0])\n",
    "    ess_zbaoabz = ess(traces_zbaoabz[:,0])\n",
    "\n",
    "    # compute kinetic temperature for traces\n",
    "    T_kin_baoab = np.mean(np.sum(traces_baoab[:,2:4]**2, axis=1)) / 2\n",
    "    T_kin_zbaoabz = np.mean(np.sum(traces_zbaoabz[:,2:4]**2, axis=1)) / 2\n",
    "\n",
    "    # compute mean configurational temperatures\n",
    "    T_conf_mean_baoab = np.mean(traces_baoab[:,5])\n",
    "    T_conf_mean_zbaoabz = np.mean(traces_zbaoabz[:,5])\n",
    "\n",
    "    # compute running average of observable y\n",
    "    y_avg_baoab = np.cumsum(traces_baoab[:,0]) / (np.arange(len(traces_baoab)) + 1)\n",
    "    y_avg_zbaoabz = np.cumsum(traces_zbaoabz[:,0]) / (np.arange(len(traces_zbaoabz)) + 1)\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 24))\n",
    "    gs = fig.add_gridspec(8, 2, height_ratios=[2, 1, 1, 1, 1, 1, 1, 1], hspace=0.5)\n",
    "\n",
    "    # --- Row 0: Contours ---\n",
    "    ax0 = fig.add_subplot(gs[0, 0])\n",
    "    ax0.contourf(X, Y, LOGZ, levels=levels, cmap='viridis')\n",
    "    ax0.plot(samples_baoab[:, 1], samples_baoab[:, 0], lw=0.7, color='red', alpha=0.7)\n",
    "    ax0.set_title(f'BAOAB (h={h}, γ={gamma}, α={alpha})')\n",
    "    ax0.set_xlabel('x'); ax0.set_ylabel('y')\n",
    "\n",
    "    ax1 = fig.add_subplot(gs[0, 1])\n",
    "    ax1.contourf(X, Y, LOGZ, levels=levels, cmap='viridis')\n",
    "    ax1.plot(samples_zbaoabz[:, 1], samples_zbaoabz[:, 0], lw=0.7, color='red', alpha=0.7)\n",
    "    ax1.set_title(f'ZBAOABZ (h={h}, γ={gamma}, α={alpha})')\n",
    "    ax1.set_xlabel('x'); ax1.set_ylabel('y')\n",
    "\n",
    "    # --- Row 1: Position traces ---\n",
    "    ax_left = fig.add_subplot(gs[1, 0])\n",
    "    ax_left.plot(traces_baoab[:,0], lw=0.7, label=\"y\")\n",
    "    ax_left.plot(traces_baoab[:,1], lw=0.7, label=\"x\")\n",
    "    ax_left.set_title(\"BAOAB trace: positions\"); ax_left.set_xlabel(\"Step\"); ax_left.legend()\n",
    "\n",
    "    ax_right = fig.add_subplot(gs[1, 1])\n",
    "    ax_right.plot(traces_zbaoabz[:,0], lw=0.7, label=\"y\")\n",
    "    ax_right.plot(traces_zbaoabz[:,1], lw=0.7, label=\"x\")\n",
    "    ax_right.set_title(\"ZBAOABZ trace: positions\"); ax_right.set_xlabel(\"Step\"); ax_right.legend()\n",
    "\n",
    "    # --- Row 2: Momentum traces ---\n",
    "    ax_left = fig.add_subplot(gs[2, 0])\n",
    "    ax_left.plot(traces_baoab[:,2], lw=0.7, label=\"p_y\")\n",
    "    ax_left.plot(traces_baoab[:,3], lw=0.7, label=\"p_x\")\n",
    "    ax_left.set_title(\"BAOAB trace: momenta\"); ax_left.set_xlabel(\"Step\"); ax_left.legend()\n",
    "\n",
    "    ax_right = fig.add_subplot(gs[2, 1])\n",
    "    ax_right.plot(traces_zbaoabz[:,2], lw=0.7, label=\"p_y\")\n",
    "    ax_right.plot(traces_zbaoabz[:,3], lw=0.7, label=\"p_x\")\n",
    "    ax_right.set_title(\"ZBAOABZ trace: momenta\"); ax_right.set_xlabel(\"Step\"); ax_right.legend()\n",
    "\n",
    "    # --- Row 3: Step size traces ---\n",
    "    ax_left = fig.add_subplot(gs[3, 0])\n",
    "    ax_left.plot(traces_baoab[:,4], lw=0.7)\n",
    "    ax_left.set_title(\"BAOAB trace: dt (step size)\"); ax_left.set_xlabel(\"Step\")\n",
    "\n",
    "    ax_right = fig.add_subplot(gs[3, 1])\n",
    "    ax_right.plot(traces_zbaoabz[:,4], lw=0.7)\n",
    "    ax_right.set_title(\"ZBAOABZ trace: dt (step size)\"); ax_right.set_xlabel(\"Step\")\n",
    "\n",
    "    # --- Row 4: Configurational Temperature traces ---\n",
    "    ax_left = fig.add_subplot(gs[4, 0])\n",
    "    ax_left.plot(traces_baoab[:,5], lw=0.7, label=\"T_conf\")\n",
    "    ax_left.hlines(T_kin_baoab, 0, len(traces_baoab), color='orange', lw=1.5, linestyle='--', label=f\"T_kin={T_kin_baoab:.3f}\")\n",
    "    ax_left.hlines(T_conf_mean_baoab, 0, len(traces_baoab), color='red', lw=1.5, linestyle=':', label=f\"T_conf_mean={T_conf_mean_baoab:.3f}\")\n",
    "    ax_left.set_title(\"BAOAB trace: Configurational vs Kinetic T\"); ax_left.set_xlabel(\"Step\"); ax_left.legend()\n",
    "\n",
    "    ax_right = fig.add_subplot(gs[4, 1])\n",
    "    ax_right.plot(traces_zbaoabz[:,5], lw=0.7, label=\"T_conf\")\n",
    "    ax_right.hlines(T_kin_zbaoabz, 0, len(traces_zbaoabz), color='orange', lw=1.5, linestyle='--', label=f\"T_kin={T_kin_zbaoabz:.3f}\")\n",
    "    ax_right.hlines(T_conf_mean_zbaoabz, 0, len(traces_zbaoabz), color='red', lw=1.5, linestyle=':', label=f\"T_conf_mean={T_conf_mean_zbaoabz:.3f}\")\n",
    "    ax_right.set_title(\"ZBAOABZ trace: Configurational vs Kinetic T\"); ax_right.set_xlabel(\"Step\"); ax_right.legend()\n",
    "\n",
    "    # --- Row 5: ESS comparison ---\n",
    "    ax_ess = fig.add_subplot(gs[5, :])\n",
    "    ax_ess.bar([\"BAOAB\", \"ZBAOABZ\"], [ess_baoab, ess_zbaoabz], color=[\"blue\", \"green\"], alpha=0.7)\n",
    "    ax_ess.set_title(\"Effective Sample Size (ESS) for y\"); ax_ess.set_ylabel(\"ESS\")\n",
    "\n",
    "    # --- Row 6: Histogram of T_conf vs T_kin ---\n",
    "    ax_hist = fig.add_subplot(gs[6, :])\n",
    "    ax_hist.hist(traces_baoab[:,5], bins=50, alpha=0.5, label=\"BAOAB T_conf\")\n",
    "    ax_hist.hist(traces_zbaoabz[:,5], bins=50, alpha=0.5, label=\"ZBAOABZ T_conf\")\n",
    "    ax_hist.axvline(T_kin_baoab, color='blue', linestyle='--', label=\"BAOAB T_kin\")\n",
    "    ax_hist.axvline(T_kin_zbaoabz, color='green', linestyle='--', label=\"ZBAOABZ T_kin\")\n",
    "    ax_hist.set_title(\"Histogram of Configurational vs Kinetic Temperature\")\n",
    "    ax_hist.set_xlabel(\"Temperature\"); ax_hist.set_ylabel(\"Frequency\"); ax_hist.legend()\n",
    "\n",
    "    # --- Row 7: Running average of observable y and x ---\n",
    "    # Compute running averages\n",
    "    y_avg_baoab = np.cumsum(traces_baoab[:,0]) / (np.arange(len(traces_baoab)) + 1)\n",
    "    x_avg_baoab = np.cumsum(traces_baoab[:,1]) / (np.arange(len(traces_baoab)) + 1)\n",
    "\n",
    "    y_avg_zbaoabz = np.cumsum(traces_zbaoabz[:,0]) / (np.arange(len(traces_zbaoabz)) + 1)\n",
    "    x_avg_zbaoabz = np.cumsum(traces_zbaoabz[:,1]) / (np.arange(len(traces_zbaoabz)) + 1)\n",
    "\n",
    "    ax_left = fig.add_subplot(gs[7, 0])\n",
    "    ax_left.plot(y_avg_baoab, lw=0.7, color='purple', label='y_avg')\n",
    "    ax_left.plot(x_avg_baoab, lw=0.7, color='green', label='x_avg')\n",
    "    ax_left.set_title(\"BAOAB: Running averages of y and x\")\n",
    "    ax_left.set_xlabel(\"Step\"); ax_left.set_ylabel(\"Average\")\n",
    "    ax_left.legend()\n",
    "\n",
    "    ax_right = fig.add_subplot(gs[7, 1])\n",
    "    ax_right.plot(y_avg_zbaoabz, lw=0.7, color='purple', label='y_avg')\n",
    "    ax_right.plot(x_avg_zbaoabz, lw=0.7, color='green', label='x_avg')\n",
    "    ax_right.set_title(\"ZBAOABZ: Running averages of y and x\")\n",
    "    ax_right.set_xlabel(\"Step\"); ax_right.set_ylabel(\"Average\")\n",
    "    ax_right.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# --- Sliders ---\n",
    "interact(plot_samplers,\n",
    "         alpha=FloatLogSlider(value=1.0, base=10, min=-2, max=2, step=0.1, description='alpha'),\n",
    "         h=FloatLogSlider(value=0.01, base=10, min=-3, max=0, step=0.1, description='h'),\n",
    "         gamma=FloatLogSlider(value=1.0, base=10, min=-2, max=2, step=0.1, description='gamma'),\n",
    "         beta=FloatLogSlider(value=1.0, base=10, min=-4, max=4, step=0.1, description='beta'));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc45703",
   "metadata": {},
   "source": [
    "# Motivating toy example: Multimodal GMM with varying mode sizes and noisy gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ee118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have 4 modes, all of different sizes with entropic barriers. Compare SGLD, SA-SGLD. SGHMC, SA-SGHMC. pSGLD and AdamSGLD.\n",
    "# KL divergence / Wasserstein-2 between empirical marginal and ground truth (available for these toy problems). Compute on a grid or analytically where possible.\n",
    "# ESS per gradient-eval (use spectral density estimator).\n",
    "# Autocorrelation time for key coordinates.\n",
    "# Trace plots and kernel density overlays with ground-truth contours.\n",
    "# Acceptance-free diagnostics: sample quantiles, mean & covariance bias.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd88827",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b196b182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study its role at temperature-zero (as an optimizer).\n",
    "# Start without gradient noise.\n",
    "# Compare SGD, mSGD, SA-SGD, SA-mSGD.\n",
    "# Contrast to Adam/RMSProp.\n",
    "# Then simulate artificial gradient noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9394ca",
   "metadata": {},
   "source": [
    "#  Hierarchical Model for Radon Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65086cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a nice hierarchical problem for Bayesian learning with curved modes with simulated gradient noise and full-batch size.\n",
    "# Then repeat with smaller batch size and tune temperature.\n",
    "# https://www.pymc.io/projects/examples/en/2021.11.0/variational_inference/GLM-hierarchical-advi-minibatch.html\n",
    "# https://brendanhasz.github.io/2018/11/15/hmm-vs-gp-part2.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa8a311",
   "metadata": {},
   "source": [
    "# Bayesian Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e365123e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Horseshoe or Laplace prior to realize benefit against SGLD/SGHMC. Remove cold posterior effect in model architecture and data augmentation. Use simple MLP MNIST. Initialize with L-BFGS.\n",
    "# Show improvements in NLL/Brier/ECE/Test acc. \n",
    "# Show pSGLD fails as we increase temperature and it only works because we are averaging over optimizer iterates.\n",
    "# Show performance with change in batch size.\n",
    "# Reference: https://arxiv.org/html/2303.05101v4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df869080",
   "metadata": {},
   "source": [
    "# Splitting vs Euler-Maruyama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94470ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
