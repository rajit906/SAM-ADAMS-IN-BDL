{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbc350e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis/aggregate_runs.ipynb\n",
    "\n",
    "# %%\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from scipy.stats import t\n",
    "\n",
    "# ------------------------\n",
    "# Config\n",
    "# ------------------------\n",
    "results_dir = \"../results\"        # folder containing run .pt files\n",
    "confidence = 0.95                 # confidence interval\n",
    "manual_run_paths = None           # optional: list of specific run paths, else None\n",
    "save_summary = True               # save summary.json in results_dir\n",
    "\n",
    "# ------------------------\n",
    "# Helper functions\n",
    "# ------------------------\n",
    "def load_runs(run_paths):\n",
    "    runs = []\n",
    "    for path in run_paths:\n",
    "        runs.append(torch.load(path))\n",
    "    return runs\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    \"\"\"\n",
    "    Compute mean and confidence interval along axis=0.\n",
    "    \"\"\"\n",
    "    data = np.array(data)\n",
    "    mean = np.mean(data, axis=0)\n",
    "    sem = np.std(data, axis=0, ddof=1) / np.sqrt(len(data))\n",
    "    h = sem * t.ppf((1 + confidence) / 2., len(data)-1)\n",
    "    return mean, h\n",
    "\n",
    "# ------------------------\n",
    "# Collect run files\n",
    "# ------------------------\n",
    "if manual_run_paths is not None:\n",
    "    run_paths = manual_run_paths\n",
    "else:\n",
    "    run_paths = glob(os.path.join(results_dir, \"*.pt\"))\n",
    "\n",
    "if len(run_paths) == 0:\n",
    "    raise ValueError(f\"No run files found in {results_dir}\")\n",
    "\n",
    "print(f\"Found {len(run_paths)} run files.\")\n",
    "runs = load_runs(run_paths)\n",
    "\n",
    "# ------------------------\n",
    "# Aggregate predictive metrics\n",
    "# ------------------------\n",
    "metrics_keys = list(runs[0][\"test_metrics\"].keys())\n",
    "agg_metrics = {}\n",
    "for k in metrics_keys:\n",
    "    vals = [r[\"test_metrics\"].get(k, np.nan) for r in runs]\n",
    "    mean, ci = mean_confidence_interval(vals, confidence)\n",
    "    agg_metrics[k] = {\"mean\": float(mean), \"ci\": float(ci)}\n",
    "\n",
    "# Display metrics\n",
    "print(\"Aggregated predictive metrics (mean ± CI):\")\n",
    "for k, v in agg_metrics.items():\n",
    "    print(f\"{k}: {v['mean']:.4f} ± {v['ci']:.4f}\")\n",
    "\n",
    "# ------------------------\n",
    "# Aggregate training/validation curves\n",
    "# ------------------------\n",
    "history_keys = [\"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\"]\n",
    "agg_curves = {}\n",
    "for key in history_keys:\n",
    "    # align lengths (truncate to shortest)\n",
    "    min_len = min(len(r[\"train_val_history\"][key]) for r in runs)\n",
    "    aligned = np.array([r[\"train_val_history\"][key][:min_len] for r in runs])\n",
    "    mean, ci = mean_confidence_interval(aligned, confidence)\n",
    "    agg_curves[key] = {\"mean\": mean, \"ci\": ci}\n",
    "\n",
    "# ------------------------\n",
    "# Plot curves with confidence intervals\n",
    "# ------------------------\n",
    "for key in history_keys:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    mean = agg_curves[key][\"mean\"]\n",
    "    ci = agg_curves[key][\"ci\"]\n",
    "    steps = np.arange(len(mean))\n",
    "    plt.plot(steps, mean, label=f\"Mean {key}\")\n",
    "    plt.fill_between(steps, mean - ci, mean + ci, alpha=0.3, color='C0')\n",
    "    plt.title(f\"{key} ± {int(confidence*100)}% CI\")\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(key)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# ------------------------\n",
    "# Optionally save aggregated summary\n",
    "# ------------------------\n",
    "if save_summary:\n",
    "    summary_path = os.path.join(results_dir, \"summary.json\")\n",
    "    summary = {\n",
    "        \"metrics\": agg_metrics,\n",
    "        \"curves\": {k: {\"mean\": agg_curves[k][\"mean\"].tolist(),\n",
    "                       \"ci\": agg_curves[k][\"ci\"].tolist()} for k in history_keys},\n",
    "        \"run_paths\": run_paths\n",
    "    }\n",
    "    with open(summary_path, \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    print(f\"Aggregated summary saved -> {summary_path}\")\n",
    "\n",
    "# %%\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
